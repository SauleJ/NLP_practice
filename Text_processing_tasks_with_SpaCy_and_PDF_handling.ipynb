{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script performs various text processing tasks on different documents.\n",
    "\n",
    "Task 1: Removing Punctuation and Stopwords from a Text File\n",
    "Utilizes SpaCy to remove punctuation, stopwords, and newline symbols from the given text file.\n",
    "\n",
    "Task 2: Printing the First Three Named Entities\n",
    "Extracts and prints the first three named entities along with their types from the text file.\n",
    "\n",
    "Task 3: Visualizing Named Entities in the Fourth Sentence\n",
    "Uses SpaCy to visualize named entities in the fourth sentence of the text file, applying custom background colors and gradients.\n",
    "\n",
    "Task 4: Removing Unnecessary Spaces and Printing the Document Text\n",
    "Removes unnecessary spaces from the text extracted from a PDF file and prints the cleaned text.\n",
    "\n",
    "Task 5: Providing POS Tag Frequencies\n",
    "Extracts text from a PDF file and calculates the frequencies of POS tags, then prints the results.\n",
    "\n",
    "Task 6: Visualizing Named Entities in the First Three Sentences\n",
    "Extracts the first three sentences from a PDF file and visualizes the named entities, applying custom styles.\n",
    "\n",
    "Task 7: Printing Stopwords in the Document Text\n",
    "Extracts text from a PDF file and prints the stopwords found in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"red\">To perform the tasks, use the text in the document tekstas.txt.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Remove all punctuation, stopwords, and newline symbols (i.e., \"\\n\") from the existing text (i.e., the entire read text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foolish Donkey salt seller carry salt bag donkey market day way cross stream day donkey suddenly tumbled stream salt bag fell water salt dissolved water bag light carry donkey happy donkey started play trick day salt seller came understand trick decided teach lesson day loaded cotton bag donkey played trick hoping cotton bag lighter dampened cotton heavy carry donkey suffered learnt lesson play trick anymore day seller happy\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "with open('tekstas.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "new_text = ' '.join(token.text for token in doc if token.text.lower() not in stop_words).replace('\\n', '').translate(str.maketrans('', '', '.,?!()[]{}:;\\\"\\''))\n",
    "\n",
    "new_text = ' '.join(word if word != ' ' * 3 else ' ' for word in new_text.split())\n",
    "\n",
    "print(new_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"red\">To perform the tasks, use the text in the document tekstas2.txt.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Print the first three named entities in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first three named entities in the text:\n",
      "The Faculty of Mathematics and Informatics of Vilnius University  ORG      Companies, agencies, institutions, etc.\n",
      "four                                                              CARDINAL Numerals that do not fall under another type\n",
      "Data Science                                                      ORG      Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "with open('tekstas2.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "entities = [(ent.text, ent.label_) for ent in doc.ents[:3]]\n",
    "\n",
    "print(\"The first three named entities in the text:\")\n",
    "for entity in entities:\n",
    "    print(f\"{entity[0].ljust(65)} {entity[1].ljust(8)} {spacy.explain(entity[1])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Visualize named entities in the fourth sentence. Change the background color of elements and apply a gradient effect (choose colors at your discretion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Span\n",
    "\n",
    "with open('tekstas2.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "PERSON = doc.vocab.strings[u'PERSON']\n",
    "\n",
    "target_word = \"Paulius\"\n",
    "positions = [token.i for token in doc if token.text == target_word]\n",
    "start_index = positions[0]\n",
    "end_index = start_index + len(target_word)\n",
    "new_ent = Span(doc, start_index, 75, label=PERSON)\n",
    "\n",
    "fourth_sentence = list(doc.sents)[3]\n",
    "\n",
    "entities = list(doc.ents) + [new_ent] \n",
    "doc.ents = entities\n",
    "\n",
    "options = {\n",
    "    \"colors\": {\"ORG\": \"linear-gradient(90deg, #00ff00, #ff0000)\",\n",
    "               \"CARDINAL\": \"linear-gradient(90deg, #ff00ff, #0000ff)\",\n",
    "               \"MONEY\": \"linear-gradient(90deg, #00ffff, #0000ff)\",\n",
    "               \"DATE\": \"linear-gradient(90deg, #00ffff, #0000ff)\",\n",
    "               \"PERSON\": \"linear-gradient(90deg, #00ffff, #0000ff)\"},\n",
    "}\n",
    "\n",
    "html_output = displacy.render(fourth_sentence, style=\"ent\", options=options, jupyter=False)\n",
    "\n",
    "with open(\"Fourth_sentence.html\", \"w\", encoding=\"utf-8\") as html_file:\n",
    "    html_file.write(html_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"red\">To perform the tasks, use the text in the document tekstas3.pdf.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Remove unnecessary spaces and print the available text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz \n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    with fitz.open(pdf_file) as pdf_document:\n",
    "        text = ''\n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_number]\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "pdf_file = 'tekstas3.pdf'\n",
    "text_from_pdf = extract_text_from_pdf(pdf_file)\n",
    "\n",
    "text_without_spaces = ' '.join(text_from_pdf.split())\n",
    "\n",
    "print(text_without_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Provide a list of POS tag frequencies in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84. ADJ   : 45\n",
      "85. ADP   : 63\n",
      "86. ADV   : 10\n",
      "87. AUX   : 15\n",
      "89. CCONJ : 15\n",
      "90. DET   : 51\n",
      "91. INTJ  : 1\n",
      "92. NOUN  : 79\n",
      "93. NUM   : 26\n",
      "94. PART  : 4\n",
      "95. PRON  : 7\n",
      "96. PROPN : 80\n",
      "97. PUNCT : 60\n",
      "98. SCONJ : 10\n",
      "100. VERB  : 33\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import fitz\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    with fitz.open(pdf_file) as pdf_document:\n",
    "        text = ''\n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_number]\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "pdf_file = 'tekstas3.pdf'\n",
    "doc = nlp(extract_text_from_pdf(pdf_file))\n",
    "\n",
    "pos_frequencies = doc.count_by(spacy.attrs.POS)\n",
    "\n",
    "for pos in sorted(pos_frequencies):\n",
    "    pos_text = doc.vocab[pos].text\n",
    "    print(f\"{pos}. {pos_text.ljust(7)} : {pos_frequencies[pos]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Visualize named entities in the first three sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Vilnius University\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (Lithuanian: Vilniaus universitetas) is a public research university, which is the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " and largest university in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lithuania\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " , as well as \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of the oldest and most prominent higher education institutions in \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Central\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Eastern Europe\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Today\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", it is \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lithuania\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "'s leading research institution, ranked among the Top \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    29%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       " Higher Education Institutions in the world.The university wa \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    s\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " founded in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1579\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " as the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jesuit\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " was the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    third\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " oldest university (after \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Cracow Academy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and the \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Albertina\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ") in the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Polish\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " Lithuanian Commonwealth.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import fitz\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    with fitz.open(pdf_file) as pdf_document:\n",
    "        text = ''\n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_number]\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "pdf_file = 'tekstas3.pdf'\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(extract_text_from_pdf(pdf_file))\n",
    "\n",
    "first_three_sentences = list(doc.sents)[:3]\n",
    "\n",
    "entities = [(ent.text, ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "\n",
    "options = {\n",
    "    \"colors\": {\"ORG\": \"linear-gradient(90deg, #00ff00, #ff0000)\",\n",
    "               \"CARDINAL\": \"linear-gradient(90deg, #ff00ff, #0000ff)\",\n",
    "               \"MONEY\": \"linear-gradient(90deg, #00ffff, #0000ff)\",\n",
    "               \"DATE\": \"linear-gradient(90deg, #00ffff, #0000ff)\",\n",
    "               \"PERSON\": \"linear-gradient(90deg, #00ffff, #0000ff)\",\n",
    "               \"LAW\": \"linear-gradient(90deg, #00ffff, #0000ff)\"},\n",
    "}\n",
    "\n",
    "html_output = displacy.render(first_three_sentences, style=\"ent\", options=options, jupyter=False)\n",
    "\n",
    "with open(\"first_three_sentences.html\", \"w\", encoding=\"utf-8\") as html_file:\n",
    "    html_file.write(html_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Print the irrelevant words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'a', 'which', 'is', 'the', 'first', 'and', 'in', 'as', 'well', 'as', 'one', 'of', 'the', 'and', 'most', 'in', 'and', 'it', 'is', \"'s\", 'among', 'the', 'Top', 'in', 'the', 'The', 'in', 'as', 'the', 'was', 'the', 'third', 'after', 'the', 'and', 'the', 'in', 'the', 'Due', 'to', 'the', 'of', 'the', 'the', 'was', 'down', 'and', 'its', 'until', 'In', 'the', 'of', 'I', 'the', 'to', 'it', 'by', 'the', 'and', 'by', 'It', 'as', 'in', 'the', 'of', 'in', 'the', 'was', 'by', 'the', 'from', 'and', 'then', 'after', 'of', 'by', 'a', 'of', 'after', 'from', 'to', 'when', 'it', 'was', 'as', 'the', 'In', 'the', 'of', 'and', 'of', 'was', 'to', 'its', 'in', 'the', 'of', 'the', 'it', 'its', 'as', 'one', 'of', 'the', 'in', 'It', 'is', 'of', 'fifteen', 'that', 'more', 'than', 'in', 'a', 'of', 'for', 'over', 'is', 'for', 'its', 'and', 'in', 'by', 'the', 'of', 'the', 'such', 'as', 'the', 'and', 'and', 'other', 'Since', 'has', 'been', 'a', 'of', 'a', 'of', 'the', 'and', 'since', 'it', 'has', 'to', 'the', 'The', 'to', 'and', 'for', 'in', 'the', 'of', 'and', 'The', 'was', 'on', 'thus', 'becoming', 'the', 'first', 'in', 'The', 'of', 'the', 'an', 'the', 'of', 'that', 'to', 'while', 'other', 'In', 'of', \"'s\", 'is', 'the', 'of', 'eleven', 'along', 'with', 'the', 'of', 'four', 'and', 'four', 'from']\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import spacy\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    with fitz.open(pdf_file) as pdf_document:\n",
    "        text = ''\n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_number]\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "pdf_file = 'tekstas3.pdf'\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "doc = nlp(extract_text_from_pdf(pdf_file))\n",
    "\n",
    "new_text = ' '.join(token.text for token in doc if token.text.lower() in stop_words)\n",
    "\n",
    "print(new_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
